:-module(dataSyntax,[
    compile_data/1,
    initCompiler/0
    ]).

/** <module> Syntax Analyzer for Kleio Data Files.
  
  Main predicate compile_data/1 
    analyses the series of tokens of a clio source data file
    this predicate is called by 'processLine'
    
    Compilation takes place on a line by line basis.
    When a segment of the data is recognized a predicate call
    is generated to store the data in a temporary structure called
    cds. 'Cds?' handling code is in the file 'data code' see dataCDS.pl .
        
    Created 10 September 1990
    Comments and stable code in Oct 90.
    
 
 @tbd Test what happens when: dia=6<RET>mes=3 %

*/
:-use_module(dataCode).
:-use_module(errors).
:-use_module(lexical).
:-use_module(reports).
:-use_module(persistence).


%% initCompiler is det.
%
% clears status of compiler. Must be called at start of new file
%
initCompiler:-
    tquoteClear,dquoteClear,!.

%% compile_data(+Tokens) is det.
%
% Parses a line of tokens. 
% The following calls are generated by the grammar bellow:
%     
% * newGroup (when a new group is detected)
% * newElement( when an explicit element is detected: element=entry)
% * endElement (when an end of element is detected: '/'
% * newAspect (when a new aspect is detected: '#' or "%")
% * newEntry (when a new entry is detected: ';')
% * storeCore (when processing core information of an element).
% 
% Except for newGroup the calls for the other precidates are acumulated
% during line processing and executed all at once at the end of the line by
% by a call to storeEls(list of calls).
%
compile_data(eof):-!,
    flushGroup,
    report([writeln('*** End of File')]).
compile_data(Tokens):-
   phrase(a_line,Tokens),!.
compile_data(Tokens):-
    error_out(['***Unable to compile ',Tokens]),!.


a_line-->group,elements(E),{storeEls(E)}.
a_line-->elements(E),{storeEls(E)}.

group-->[(names,N)],dataflag1,{newGroup(N),!}.
group-->fillSpace(__S),[(names,N)],dataflag1,{newGroup(N),!}.

elements([E|R])-->element(E),elements(R).
elements([])   -->[].

% triple quote handling 
% Everything inside """ ..... ... """ is stored as is
element(storeCore(TQ)) --> [(tquote,TQ)],{tquoteOff,tquoteEnter,!}.
element(storeCore(TQ)) --> [(tquote,TQ)],{tquoteOn,tquoteExit,!}.
element(storeCore(D)) --> [(dataflag,N)],{tquoteOn,data_flag_char(N,C),name(D,[C]),!}.
element(storeCore(D)) --> [(return,R)],{tquoteOn,name(D,[R]),!}.
element(storeCore(R)) --> [(L,R)], { tquoteOn,memberchk(L,[fill,names,number,dquote]),!}.
element(storeCore(D)) --> [(__C,R)],{tquoteOn,%format('Got Unknown code: ~w:~w~n',[C,R]),
                                    name(D,[R]),!}.
% double quote handling 
% Everything inside " ... " is stored as is
element(storeCore(DQ)) --> [(dquote,DQ)],{dquoteOff,dquoteEnter,!}.
element(storeCore(DQ)) --> [(dquote,DQ)],{dquoteOn,dquoteExit,!}.
element(storeCore(D)) --> [(dataflag,N)],{dquoteOn,data_flag_char(N,C),name(D,[C]),!}.
element(true) --> [(return,_)],{dquoteOn,!}. % whithin double quotes we skip returns
element(storeCore(' ')) --> [(fill,__)],{dquoteOn},!.
element(storeCore(R)) --> [(L,R)], { dquoteOn,memberchk(L,[names,number]),!}.
element(storeCore(D)) --> [(__C,R)],{dquoteOn,%format('Got Unknown code: ~w:~w~n',[C,R]),
                                    name(D,[R]),!}.

% every fill squence is stored as a single space
%    and returns are skipped %
element(storeCore(' '))-->fillSpace(__S),{!}. % mudar aqui o tratamento do espaco %
element(newElement(E)) -->[(names,E)],dataflag3,{!}. % must precede store core %
element(storeCore(E))  -->[(names,E)],{!}.
element(endElement)    -->dataflag2,{!}.
element(true)          -->[(return,__R)],{!}. %,{name(S,[R]),storeCore(S),!}.%
element(newEntry)      -->[(dataflag,8)],{!}.
element(newAspect(original))-->[(dataflag,5)],{!}.
element(newAspect(comment))-->[(dataflag,4)],{!}.
element(storeCore(S))  -->[(dataflag,10)],[(dataflag,N)],
		               {data_flag_char(N,C),name(S,[C]),!}.
element(storeCore(S))  -->[(dataflag,10)],[(__T,V)],{name(S,[V]),!}.
element(storeCore(N))  -->[(number,N)],{!}.
element(storeCore(QS)) -->[(dqstring,QS)],{!}. 
element(storeCore(S)) -->[(dataflag,F)],
                        {!,data_flag_char(F,C),name(S,[C])}. % we must take dataflags not used up to here literally
element(storeCore(S))  -->[(__T,V)],{name(S,[V]),!}.

fillSpace(S)-->[(fill,S)],{!}.

edef(E)-->names(E),dataflag3,{!}.

dataflag1-->[(dataflag,1)],{!}.
dataflag2-->[(dataflag,2)],{!}.
dataflag5-->[(dataflag,5)],{!}.
dataflag4-->[(dataflag,4)],{!}.
dataflag3-->[(dataflag,3)],{!}.
dataflag8-->[(dataflag,8)],{!}.
dataflag9-->[(dataflag,9)],{!}.
dataflag10-->[(dataflag,10)],{!}.

% IMPORTANT ensure that tquoteClear is called at start of file processing.
tquoteOn :- get_value(tquote,true).
tquoteOff :- get_value(tquote,F), !,F=false.
tquoteOff :-!.
tquoteEnter :- put_value(tquote,true).
tquoteExit :- put_value(tquote,false).
tquoteClear :- put_value(tquote,false), dquoteClear.

% IMPORTANT ensure that dquoteClear is called at start of file processing.
dquoteOn :- get_value(dquote,true).
dquoteOff :- get_value(dquote,F), !,F=false.
dquoteOff :-!.
dquoteEnter :- put_value(dquote,true).
dquoteExit :- put_value(dquote,false).
dquoteClear :- put_value(dquote,false).

% reserved chars in core information %
reschar([DF1,DF2,DF3,DF4,DF5,DF6,DF7,DF8]):-
               data_flag_char(1,DF1),
               data_flag_char(2,DF2),
               data_flag_char(3,DF3),
               data_flag_char(4,DF4),
               data_flag_char(5,DF5),
               data_flag_char(6,DF6),
               data_flag_char(7,DF7),
               data_flag_char(8,DF8),!.


:-begin_tests(dataSyntax).

test(compile_data_with_tquotes):-
    Chars = `""" " \r " """\r`,
    string_codes(String,Chars),
    format('Line:  ~w~n',[String]),
    lexical:test_lexical(Chars,TypedChars),
    format('Types:  ~w~n',[TypedChars]),
    get_tokens(dat,TypedChars,Tokens),
    format('Tokens: ~w~n',[Tokens]),
    compile_data(Tokens).

test(compile_data_with_quotes):-
    Chars = ` b$a,c    acto$asf.4#"htpp://timelink.uc.pt?\\\"xpto\\\""/24/5/1958/obs=url\r`,
    string_codes(String,Chars),
    format('~nLine:  ~w~n',[String]),
    lexical:test_lexical(Chars,TypedChars),
    % format('Types ~w~n:',[TypedChars]),
    get_tokens(dat,TypedChars,Tokens),
    format('~nTokens~w~n:',[Tokens]),
    compile_data(Tokens).

test(compile_data_with_pseudo_numbers):-
    Chars = `date$string=5.10.1765`,
    string_codes(String,Chars),
    format('Line:  ~w~n',[String]),
    lexical:test_lexical(Chars,TypedChars),
    format('Types:  ~w~n',[TypedChars]),
    get_tokens(dat,TypedChars,Tokens),
    format('Tokens: ~w~n',[Tokens]),
    compile_data(Tokens).

:- end_tests(dataSyntax).







